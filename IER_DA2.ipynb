{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9488161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de339300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the documents and the query\n",
    "D1 = \"\"\"Since OpenAI released its blockbuster bot ChatGPT in November, users have casually \n",
    "experimented with the tool, with even Insider reporters trying to simulate news stories or \n",
    "message potential dates.To older millennials who grew up with IRC chat rooms — a text \n",
    "instant message system — the personal tone of conversations with the bot can evoke the \n",
    "experience of chatting online. But ChatGPT, the latest in technology known as \"large \n",
    "language model tools,\" doesn't speak with sentience and doesn't \"think\" the way people do.\"\"\"\n",
    "    \n",
    "    \n",
    "D2 = \"\"\"Other tech companies like Google and Meta have developed their own large language \n",
    "model tools, which use programs that take in human prompts and devise sophisticated \n",
    "responses. OpenAI, in a revolutionary move, also created a user interface that is letting the \n",
    "general public experiment with it directly. Some recent efforts to use chat bots for real-world \n",
    "services have proved troubling — with odd results. The mental health company Koko came \n",
    "under fire this month after its founder wrote about how the company used GPT-3 in an \n",
    "experiment to reply to users.\"\"\"\n",
    "D3 =  \"\"\"The founder of the controversial DoNotPay service, which claims its GPT-3-driven chat \n",
    "bot helps users resolve customer service disputes, also said an AI \"lawyer\" would advise \n",
    "defendants in actual courtroom traffic cases in real time, though he later walked that\n",
    "back over concerns about its risks. Chat GPT is an AI Chatbot developed by Open AI. The \n",
    "chatbot has a language-based model that the developer fine-tunes for human interaction in a \n",
    "conversational manner. Effectively it’s a simulated chatbot primarily designed for customer \n",
    "service; people use it for various other purposes too though. These range from writing essays \n",
    "to drafting business plans, to generating code. But what is it and what can it really do? \"\"\"\n",
    "\n",
    "D4= \"\"\"Chat GPT is an AI chatbot auto-generative system created by Open AI for online \n",
    "customer care. It is a pre-trained generative chat, which makes use of (NLP) Natural \n",
    "Language Processing. The source of its data is textbooks, websites, and various articles, \n",
    "which it uses to model its own language for responding to human interaction. The main \n",
    "feature of Chat GPT is generating responses like those humans would provide, in a text box. \n",
    "Therefore, it is suitable for chatbots, AI system conversations, and virtual \n",
    "assistants. However, it can also give natural answers to questions in a conversational tone and \n",
    "can generate stories poems and more. Moreover, it can: Write code, Write an article or blog \n",
    "post, Translate, Debug, Write a story/poem, Recommend chords and lyrics\"\"\"\n",
    "\n",
    "q = \"OpenAI chatbot chatGPT\"\n",
    "\n",
    "# Create a list of documents\n",
    "documents = [D1, D2, D3, D4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75c996de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenise words while ignoring punctuation\n",
    "    tokeniser = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokeniser.tokenize(text)\n",
    "    \n",
    "    # Lowercase and lemmatise \n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    lemmas = [lemmatiser.lemmatize(token.lower(), pos='v') for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    keywords= [lemma for lemma in lemmas if lemma not in stopwords.words('english')]\n",
    "    return keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "183f977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveResults(D, query):\n",
    "    #Takes in a set of documents and a query statement\n",
    "    x = pd.DataFrame({'text': D})\n",
    "    # Tokenize each document in the 'text' column and preprocess the text\n",
    "    tokenized_docs = [preprocess_text(doc) for doc in x['text']]\n",
    "\n",
    "    # Create a consolidated list to make a vocabulary of all terms\n",
    "    # Flatten the list of tokenized documents into a single list of tokens\n",
    "    all_tokens = [token for doc in tokenized_docs for token in doc]\n",
    "\n",
    "    #Get a list of unique tokens\n",
    "    unique_tokens = list(set(all_tokens))\n",
    "    \n",
    "    #Uncomment to print all unique tokens\n",
    "    #print(unique_tokens)\n",
    "\n",
    "    # Create a dictionary to store the document frequency for each token\n",
    "    doc_freq = {token:0 for token in unique_tokens}\n",
    "\n",
    "    # Iterate through each tokenized document and update the document frequency\n",
    "    # how many times a term appears in a document\n",
    "    for doc_tokens in tokenized_docs:\n",
    "        for token in set(doc_tokens):\n",
    "            doc_freq[token] += 1\n",
    "    # Convert the dictionary to a dataframe\n",
    "    df_doc_freq = pd.DataFrame.from_dict(doc_freq, orient='index', columns=['document_frequency'])\n",
    "    \n",
    "    #Uncomment to print dataframe for document frequency\n",
    "    #print(df_doc_freq)\n",
    "    \n",
    "    # Sort the data frame by document frequency in descending order\n",
    "    df_doc_freq = df_doc_freq.sort_values(by=['document_frequency'], ascending=False)\n",
    "    \n",
    "    # Get the total number of documents in the corpus\n",
    "    num_docs = len(x)\n",
    "\n",
    "    # Calculate the idf for each term in the corpus\n",
    "    df_doc_freq['idf'] = df_doc_freq.apply(lambda row: math.log(num_docs / row['document_frequency']), axis=1)\n",
    "    \n",
    "    \n",
    "    #Print idf values dataframe\n",
    "    #print(df_doc_freq)\n",
    "    # Sort the dataframe by idf in ascending order\n",
    "    df_doc_freq = df_doc_freq.sort_values(by=['idf'], ascending=True)\n",
    "    # Create a dataframe to store the term frequency for each term in each document\n",
    "    df_tf = pd.DataFrame(columns=unique_tokens)\n",
    "\n",
    "    # Iterate through each document in the corpus\n",
    "    for i, doc_tokens in enumerate(tokenized_docs):\n",
    "        # Create a dictionary to store the term frequency for the current document\n",
    "        term_freq = {token:0 for token in unique_tokens}\n",
    "\n",
    "        # Iterate through each token in the current document and update the term frequency\n",
    "        for token in doc_tokens:\n",
    "            term_freq[token] += 1\n",
    "\n",
    "        # Calculate the term frequency using the formula tf_ij = 1 + log(f_ij)\n",
    "        for token in unique_tokens:\n",
    "            tf_ij = 1 + math.log(term_freq[token]) if term_freq[token] > 0 else 0\n",
    "            df_tf.loc[i, token] = tf_ij\n",
    "\n",
    "    df_doc_freq = df_doc_freq.sort_index(axis=0, ascending=True)\n",
    "\n",
    "    df_tf = df_tf.sort_index(axis=1)\n",
    "    \n",
    "    #To print term frequency matrix\n",
    "    #print(df_tf)\n",
    "\n",
    "    tf_idf_matrix = df_tf.mul(df_doc_freq ['idf'], axis=1)\n",
    "    \n",
    "    #Print tf_idf\n",
    "    #print(tf_idf_matrix)\n",
    "    \n",
    "    # Preprocess the query text\n",
    "    query_tokens = preprocess_text(query)\n",
    "    # Calculate the TF-IDF vector for the query\n",
    "    query_tfidf = np.zeros((1, len(df_doc_freq)))\n",
    "    df_tfq = pd.DataFrame(columns=unique_tokens)\n",
    "\n",
    "    \n",
    "    for token in query_tokens:\n",
    "        if token in df_doc_freq.index:\n",
    "            idx = df_doc_freq.index.get_loc(token)\n",
    "            query_tfidf[0, idx] += 1\n",
    "\n",
    "    query_tfidf = query_tfidf[0]\n",
    "    #print(query_tfidf)\n",
    "    for i in range(len(query_tfidf)):\n",
    "        l = query_tfidf[i]\n",
    "        if(l != 0):\n",
    "            query_tfidf[i] = 1 + np.log(query_tfidf[i])\n",
    "\n",
    "    query_vector = np.array(query_tfidf).reshape(1, -1)\n",
    "\n",
    "    sim = {}\n",
    "    l = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        doc1 = np.array(tf_idf_matrix.iloc[i].tolist()).reshape(1, -1)\n",
    "        similarity = cosine_similarity(query_vector, doc1)\n",
    "        dname = \"Document \"+ str(i+1)\n",
    "        sim[dname] = similarity[0][0]\n",
    "        l.append(similarity[0][0])\n",
    "\n",
    "    x['qSim'] = l\n",
    "\n",
    "    #The ranked documents are\n",
    "    print(x.sort_values(by=['qSim'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af9fb380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text      qSim\n",
      "0  Since OpenAI released its blockbuster bot Chat...  0.205515\n",
      "2  The founder of the controversial DoNotPay serv...  0.088627\n",
      "1  Other tech companies like Google and Meta have...  0.046062\n",
      "3  Chat GPT is an AI chatbot auto-generative syst...  0.039781\n"
     ]
    }
   ],
   "source": [
    "retrieveResults(documents, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90886cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text      qSim\n",
      "2  The founder of the controversial DoNotPay serv...  0.146293\n",
      "0  Since OpenAI released its blockbuster bot Chat...  0.000000\n",
      "1  Other tech companies like Google and Meta have...  0.000000\n",
      "3  Chat GPT is an AI chatbot auto-generative syst...  0.000000\n"
     ]
    }
   ],
   "source": [
    "retrieveResults(documents, \"controversial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e722f6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
